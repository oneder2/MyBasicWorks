2024-11-24 15:35:30 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-24 15:35:30 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-48-generic-x86_64-with-glibc2.39
2024-11-24 15:35:30 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-24 15:35:30 [scrapy.extensions.telnet] INFO: Telnet Password: 543ceee3aaeb05b8
2024-11-24 15:35:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-24 15:35:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-11-24 15:35:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-24 15:35:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-24 15:35:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-24 15:35:30 [scrapy.core.engine] INFO: Spider opened
2024-11-24 15:35:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-24 15:35:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-24 15:35:40 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2024-11-24 15:35:40 [scrapy.core.engine] INFO: Closing spider (shutdown)
2024-11-24 15:35:44 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2024-11-24 15:35:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'downloader/request_bytes': 212,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'elapsed_time_seconds': 13.482555,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2024, 11, 24, 20, 35, 44, 389476, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/INFO': 12,
 'memusage/max': 66039808,
 'memusage/startup': 66039808,
 'responses_per_minute': None,
 'retry/count': 1,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2024, 11, 24, 20, 35, 30, 906921, tzinfo=datetime.timezone.utc)}
2024-11-24 15:35:44 [scrapy.core.engine] INFO: Spider closed (shutdown)
2024-11-24 15:39:54 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-24 15:39:54 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-48-generic-x86_64-with-glibc2.39
2024-11-24 15:39:54 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-24 15:39:54 [scrapy.extensions.telnet] INFO: Telnet Password: 0e6c12141f1f9b76
2024-11-24 15:39:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-24 15:39:54 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-11-24 15:39:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-24 15:39:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-24 15:39:54 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-24 15:39:54 [scrapy.core.engine] INFO: Spider opened
2024-11-24 15:39:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-24 15:39:54 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-24 15:40:02 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2024-11-24 15:40:02 [scrapy.core.engine] INFO: Closing spider (shutdown)
2024-11-24 15:40:06 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2024-11-24 15:40:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'downloader/request_bytes': 212,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'elapsed_time_seconds': 11.59699,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2024, 11, 24, 20, 40, 6, 127710, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/INFO': 12,
 'memusage/max': 66060288,
 'memusage/startup': 66060288,
 'responses_per_minute': None,
 'retry/count': 1,
 'retry/reason_count/twisted.web._newclient.ResponseNeverReceived': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2024, 11, 24, 20, 39, 54, 530720, tzinfo=datetime.timezone.utc)}
2024-11-24 15:40:06 [scrapy.core.engine] INFO: Spider closed (shutdown)
2024-11-24 15:42:29 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-24 15:42:29 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-48-generic-x86_64-with-glibc2.39
2024-11-24 15:42:29 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-24 15:42:29 [scrapy.extensions.telnet] INFO: Telnet Password: 33208fb7a03e59d5
2024-11-24 15:42:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-24 15:42:29 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-11-24 15:42:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-24 15:42:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-24 15:42:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-24 15:42:29 [scrapy.core.engine] INFO: Spider opened
2024-11-24 15:42:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-24 15:42:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-24 15:42:29 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-24 15:42:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 215,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 615,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.155061,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 24, 20, 42, 29, 321541, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/INFO': 10,
 'memusage/max': 66039808,
 'memusage/startup': 66039808,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2024, 11, 24, 20, 42, 29, 166480, tzinfo=datetime.timezone.utc)}
2024-11-24 15:42:29 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-24 15:49:06 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-24 15:49:06 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-48-generic-x86_64-with-glibc2.39
2024-11-24 15:49:06 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-24 15:49:06 [scrapy.extensions.telnet] INFO: Telnet Password: c3ef7792a02614d8
2024-11-24 15:49:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-24 15:49:06 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-24 15:49:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-24 15:49:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-24 15:49:06 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-24 15:49:06 [scrapy.core.engine] INFO: Spider opened
2024-11-24 15:49:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-24 15:49:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-24 15:49:07 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-24 15:49:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 281,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 681,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.153258,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 24, 20, 49, 7, 26070, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/INFO': 10,
 'memusage/max': 65941504,
 'memusage/startup': 65941504,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2024, 11, 24, 20, 49, 6, 872812, tzinfo=datetime.timezone.utc)}
2024-11-24 15:49:07 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-24 15:54:27 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-24 15:54:27 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-48-generic-x86_64-with-glibc2.39
2024-11-24 15:55:10 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-24 15:55:10 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-48-generic-x86_64-with-glibc2.39
2024-11-24 16:04:09 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-24 16:04:09 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-48-generic-x86_64-with-glibc2.39
2024-11-24 16:04:34 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-24 16:04:34 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-48-generic-x86_64-with-glibc2.39
2024-11-24 16:04:34 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-24 16:04:34 [scrapy.extensions.telnet] INFO: Telnet Password: 3b0d888e981fa475
2024-11-24 16:04:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-24 16:04:34 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-24 16:04:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-24 16:04:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-24 16:04:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-24 16:04:34 [scrapy.core.engine] INFO: Spider opened
2024-11-24 16:04:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-24 16:04:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-24 16:04:35 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-24 16:04:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 39978,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.792967,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 24, 21, 4, 35, 554763, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 133808,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/INFO': 10,
 'memusage/max': 66043904,
 'memusage/startup': 66043904,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2024, 11, 24, 21, 4, 34, 761796, tzinfo=datetime.timezone.utc)}
2024-11-24 16:04:35 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 13:10:55 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 13:10:55 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 13:10:55 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 13:10:55 [scrapy.extensions.telnet] INFO: Telnet Password: ada90cca387d4e6b
2024-11-25 13:10:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 13:10:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 13:10:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 13:10:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 13:10:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-25 13:10:55 [scrapy.core.engine] INFO: Spider opened
2024-11-25 13:10:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 13:10:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 13:10:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=8168248b9ee95a0f94ce0d79855200ff&wts=1732481551> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spiders/__init__.py", line 86, in _parse
    return self.parse(response, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 26, in parse
    data_dict = {bvid, name, title, desc, stat}
                       ^^^^
NameError: name 'name' is not defined. Did you mean: 'self.name'?
2024-11-25 13:10:56 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 13:10:56 [scrapy.extensions.feedexport] INFO: Stored json feed (0 items) in: data.json
2024-11-25 13:10:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 40496,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.976584,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 25, 18, 10, 56, 472999, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 135913,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'memusage/max': 65675264,
 'memusage/startup': 65675264,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2024, 11, 25, 18, 10, 55, 496415, tzinfo=datetime.timezone.utc)}
2024-11-25 13:10:56 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 13:12:25 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 13:12:25 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 13:12:25 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 13:12:25 [scrapy.extensions.telnet] INFO: Telnet Password: 4772a6eb1ae21634
2024-11-25 13:12:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 13:12:25 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 13:12:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 13:12:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 13:12:25 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-25 13:12:25 [scrapy.core.engine] INFO: Spider opened
2024-11-25 13:12:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 13:12:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 13:12:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=8168248b9ee95a0f94ce0d79855200ff&wts=1732481551> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spiders/__init__.py", line 86, in _parse
    return self.parse(response, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 14, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 13:12:26 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 13:12:26 [scrapy.extensions.feedexport] INFO: Stored json feed (0 items) in: data.json
2024-11-25 13:12:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 425,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.872283,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 25, 18, 12, 26, 427580, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'memusage/max': 66330624,
 'memusage/startup': 66330624,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2024, 11, 25, 18, 12, 25, 555297, tzinfo=datetime.timezone.utc)}
2024-11-25 13:12:26 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 13:12:43 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 13:12:43 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 13:12:43 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 13:12:43 [scrapy.extensions.telnet] INFO: Telnet Password: d32d5c358e294a5c
2024-11-25 13:12:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 13:12:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 13:12:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 13:12:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 13:12:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-25 13:12:43 [scrapy.core.engine] INFO: Spider opened
2024-11-25 13:12:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 13:12:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 13:12:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=8168248b9ee95a0f94ce0d79855200ff&wts=1732481551> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spiders/__init__.py", line 86, in _parse
    return self.parse(response, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 14, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 13:12:44 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 13:12:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 425,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.86977,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 25, 18, 12, 44, 686, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 66019328,
 'memusage/startup': 66019328,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2024, 11, 25, 18, 12, 43, 130916, tzinfo=datetime.timezone.utc)}
2024-11-25 13:12:44 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 13:17:58 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 13:17:58 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 13:17:58 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 13:17:58 [scrapy.extensions.telnet] INFO: Telnet Password: 3462693c0fae4fde
2024-11-25 13:17:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 13:17:58 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 13:17:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 13:17:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 13:17:58 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-25 13:17:58 [scrapy.core.engine] INFO: Spider opened
2024-11-25 13:17:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 13:17:58 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 13:17:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spiders/__init__.py", line 86, in _parse
    return self.parse(response, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 26, in parse
    data_dict = {bvid, name, title, desc, stat}
                       ^^^^
NameError: name 'name' is not defined. Did you mean: 'self.name'?
2024-11-25 13:17:59 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 13:17:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 40490,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.92051,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 25, 18, 17, 59, 73229, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 135913,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 66031616,
 'memusage/startup': 66031616,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2024, 11, 25, 18, 17, 58, 152719, tzinfo=datetime.timezone.utc)}
2024-11-25 13:17:59 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 13:18:10 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 13:18:10 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 13:18:10 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 13:18:10 [scrapy.extensions.telnet] INFO: Telnet Password: 2222036d47b0f11f
2024-11-25 13:18:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 13:18:10 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 13:18:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 13:18:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 13:18:10 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-25 13:18:10 [scrapy.core.engine] INFO: Spider opened
2024-11-25 13:18:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 13:18:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 13:18:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spiders/__init__.py", line 86, in _parse
    return self.parse(response, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 26, in parse
    data_dict = {bvid, name, title, desc, stat}
                       ^^^^
NameError: name 'name' is not defined. Did you mean: 'self.name'?
2024-11-25 13:18:11 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 13:18:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 40487,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.94076,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 25, 18, 18, 11, 160461, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 135913,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 66056192,
 'memusage/startup': 66056192,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2024, 11, 25, 18, 18, 10, 219701, tzinfo=datetime.timezone.utc)}
2024-11-25 13:18:11 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 13:19:19 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 13:19:19 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 13:19:19 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 13:19:19 [scrapy.extensions.telnet] INFO: Telnet Password: 176df015b0c0287f
2024-11-25 13:19:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 13:19:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 13:19:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 13:19:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 13:19:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-25 13:19:19 [scrapy.core.engine] INFO: Spider opened
2024-11-25 13:19:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 13:19:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 13:19:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spiders/__init__.py", line 86, in _parse
    return self.parse(response, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 27, in parse
    data_dict = {bvid, name, title, desc, stat}
                       ^^^^
NameError: name 'name' is not defined. Did you mean: 'self.name'?
2024-11-25 13:19:20 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 13:19:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 40483,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 1.176598,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 25, 18, 19, 20, 338367, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 135913,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 65978368,
 'memusage/startup': 65978368,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2024, 11, 25, 18, 19, 19, 161769, tzinfo=datetime.timezone.utc)}
2024-11-25 13:19:20 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 13:20:11 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 13:20:11 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 13:20:11 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 13:20:11 [scrapy.extensions.telnet] INFO: Telnet Password: f24b5596894fa979
2024-11-25 13:20:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 13:20:11 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 13:20:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 13:20:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 13:20:11 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-25 13:20:11 [scrapy.core.engine] INFO: Spider opened
2024-11-25 13:20:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 13:20:11 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 13:20:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spiders/__init__.py", line 86, in _parse
    return self.parse(response, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 28, in parse
    data_dict = {bvid, name, title, desc, stat}
                       ^^^^
NameError: name 'name' is not defined. Did you mean: 'self.name'?
2024-11-25 13:20:12 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 13:20:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 40494,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.954902,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 25, 18, 20, 12, 911688, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 135912,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 66060288,
 'memusage/startup': 66060288,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2024, 11, 25, 18, 20, 11, 956786, tzinfo=datetime.timezone.utc)}
2024-11-25 13:20:12 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 13:23:32 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 13:23:32 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 13:23:32 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 13:23:32 [scrapy.extensions.telnet] INFO: Telnet Password: 09defa88da306729
2024-11-25 13:23:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 13:23:32 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 13:23:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 13:23:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 13:23:32 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-25 13:23:32 [scrapy.core.engine] INFO: Spider opened
2024-11-25 13:23:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 13:23:32 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 13:23:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spiders/__init__.py", line 86, in _parse
    return self.parse(response, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 30, in parse
    data_dict = {bvid, author, title, desc, stat}
                                      ^^^^
NameError: name 'desc' is not defined
2024-11-25 13:23:33 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 13:23:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 40484,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.963743,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 25, 18, 23, 33, 920704, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 135912,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 66052096,
 'memusage/startup': 66052096,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2024, 11, 25, 18, 23, 32, 956961, tzinfo=datetime.timezone.utc)}
2024-11-25 13:23:33 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 13:23:43 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 13:23:43 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 13:23:43 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 13:23:43 [scrapy.extensions.telnet] INFO: Telnet Password: 16411827568af91a
2024-11-25 13:23:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 13:23:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 13:23:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 13:23:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 13:23:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-25 13:23:43 [scrapy.core.engine] INFO: Spider opened
2024-11-25 13:23:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 13:23:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 13:23:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spiders/__init__.py", line 86, in _parse
    return self.parse(response, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 30, in parse
    data_dict = {bvid, author, title, desc, stat}
                                      ^^^^
NameError: name 'desc' is not defined
2024-11-25 13:23:44 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 13:23:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 40514,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.939938,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 25, 18, 23, 44, 83193, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 135912,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 66064384,
 'memusage/startup': 66064384,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2024, 11, 25, 18, 23, 43, 143255, tzinfo=datetime.timezone.utc)}
2024-11-25 13:23:44 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 13:24:12 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 13:24:12 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 13:24:12 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 13:24:12 [scrapy.extensions.telnet] INFO: Telnet Password: bdbd14c8f53e574b
2024-11-25 13:24:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 13:24:12 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 13:24:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 13:24:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 13:24:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-25 13:24:12 [scrapy.core.engine] INFO: Spider opened
2024-11-25 13:24:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 13:24:12 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 13:24:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spiders/__init__.py", line 86, in _parse
    return self.parse(response, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 30, in parse
    data_dict = {bvid, author, title, description, vew_amount}
                                                   ^^^^^^^^^^
NameError: name 'vew_amount' is not defined. Did you mean: 'view_amount'?
2024-11-25 13:24:13 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 13:24:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 40497,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.996184,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 25, 18, 24, 13, 174675, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 135912,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 66170880,
 'memusage/startup': 66170880,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2024, 11, 25, 18, 24, 12, 178491, tzinfo=datetime.timezone.utc)}
2024-11-25 13:24:13 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 13:24:40 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 13:24:40 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 13:24:40 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 13:24:40 [scrapy.extensions.telnet] INFO: Telnet Password: 9ae8be1e0aebbfd2
2024-11-25 13:24:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 13:24:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 13:24:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 13:24:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 13:24:40 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-25 13:24:40 [scrapy.core.engine] INFO: Spider opened
2024-11-25 13:24:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 13:24:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 13:24:41 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 13:24:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 40494,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.913832,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 25, 18, 24, 41, 18787, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 135912,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/INFO': 10,
 'memusage/max': 65929216,
 'memusage/startup': 65929216,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2024, 11, 25, 18, 24, 40, 104955, tzinfo=datetime.timezone.utc)}
2024-11-25 13:24:41 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 13:25:03 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 13:25:03 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 13:25:03 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 13:25:03 [scrapy.extensions.telnet] INFO: Telnet Password: 2ed7aa84ad014489
2024-11-25 13:25:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 13:25:03 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 13:25:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 13:25:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 13:25:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-25 13:25:03 [scrapy.core.engine] INFO: Spider opened
2024-11-25 13:25:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 13:25:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598>
2024-11-25 13:25:04 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 13:25:04 [scrapy.extensions.feedexport] INFO: Stored json feed (0 items) in: data.json
2024-11-25 13:25:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 40506,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.836426,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 25, 18, 25, 4, 73206, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 135912,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/ERROR': 100,
 'log_count/INFO': 11,
 'memusage/max': 66236416,
 'memusage/startup': 66236416,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2024, 11, 25, 18, 25, 3, 236780, tzinfo=datetime.timezone.utc)}
2024-11-25 13:25:04 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 13:26:50 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 13:26:50 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 13:26:50 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 13:26:50 [scrapy.extensions.telnet] INFO: Telnet Password: b66d178f585a816e
2024-11-25 13:26:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 13:26:50 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 13:26:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 13:26:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 13:26:50 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-25 13:26:50 [scrapy.core.engine] INFO: Spider opened
2024-11-25 13:26:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 13:26:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 13:26:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spiders/__init__.py", line 86, in _parse
    return self.parse(response, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 17, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 13:26:51 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 13:26:51 [scrapy.extensions.feedexport] INFO: Stored csv feed (0 items) in: data.csv
2024-11-25 13:26:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 425,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.893666,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 25, 18, 26, 51, 311090, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 11,
 'memusage/max': 66326528,
 'memusage/startup': 66326528,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2024, 11, 25, 18, 26, 50, 417424, tzinfo=datetime.timezone.utc)}
2024-11-25 13:26:51 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 13:34:56 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 13:34:56 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 13:34:56 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 13:34:56 [scrapy.extensions.telnet] INFO: Telnet Password: 8515e7940879866c
2024-11-25 13:34:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 13:34:56 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 13:34:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 13:34:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 13:34:56 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-25 13:34:56 [scrapy.core.engine] INFO: Spider opened
2024-11-25 13:34:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 13:34:56 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 13:34:57 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 13:34:57 [scrapy.extensions.feedexport] INFO: Stored csv feed (100 items) in: data.csv
2024-11-25 13:34:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 40634,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.802287,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 25, 18, 34, 57, 280771, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 135953,
 'httpcompression/response_count': 1,
 'item_scraped_count': 100,
 'items_per_minute': None,
 'log_count/INFO': 11,
 'memusage/max': 66310144,
 'memusage/startup': 66310144,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2024, 11, 25, 18, 34, 56, 478484, tzinfo=datetime.timezone.utc)}
2024-11-25 13:34:57 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 22:19:18 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 22:19:18 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 22:19:18 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 22:19:18 [scrapy.extensions.telnet] INFO: Telnet Password: c571da53ceb02ac6
2024-11-25 22:19:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 22:19:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 22:19:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 22:19:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 22:19:18 [scrapy.middleware] INFO: Enabled item pipelines:
['scrapy17.pipelines.Scrapy17Pipeline']
2024-11-25 22:19:18 [scrapy.core.engine] INFO: Spider opened
2024-11-25 22:19:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 22:19:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 22:19:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 36, in parse
    item['description'] = description
    ~~~~^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/item.py", line 98, in __setitem__
    raise KeyError(f"{self.__class__.__name__} does not support field: {key}")
KeyError: 'Scrapy17Item does not support field: description'
2024-11-25 22:19:20 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 22:19:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 40335,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 1.470163,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 26, 3, 19, 20, 275553, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 134885,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 65986560,
 'memusage/startup': 65986560,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2024, 11, 26, 3, 19, 18, 805390, tzinfo=datetime.timezone.utc)}
2024-11-25 22:19:20 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 22:20:36 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 22:20:36 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 22:20:36 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 22:20:36 [scrapy.extensions.telnet] INFO: Telnet Password: d0f9d6b468deb964
2024-11-25 22:20:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 22:20:36 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 22:20:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 22:20:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 22:20:36 [scrapy.middleware] INFO: Enabled item pipelines:
['scrapy17.pipelines.Scrapy17Pipeline']
2024-11-25 22:20:36 [scrapy.core.engine] INFO: Spider opened
2024-11-25 22:20:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 22:20:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 22:20:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=7ad7b1dd0d54a58e9641bce4b7751221&wts=1732558598> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 13, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 22:20:42 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 22:20:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 425,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 5.549097,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 26, 3, 20, 42, 235336, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 66056192,
 'memusage/startup': 66056192,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2024, 11, 26, 3, 20, 36, 686239, tzinfo=datetime.timezone.utc)}
2024-11-25 22:20:42 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 22:22:26 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 22:22:26 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 22:22:26 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 22:22:26 [scrapy.extensions.telnet] INFO: Telnet Password: 98dc8ea8d1146578
2024-11-25 22:22:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 22:22:26 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 22:22:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 22:22:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 22:22:26 [scrapy.middleware] INFO: Enabled item pipelines:
['scrapy17.pipelines.Scrapy17Pipeline']
2024-11-25 22:22:26 [scrapy.core.engine] INFO: Spider opened
2024-11-25 22:22:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 22:22:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 22:22:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=da73f3537c5860b290c96f96aeaa33c1&wts=1732591275> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 36, in parse
    item['description'] = description
    ~~~~^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/item.py", line 98, in __setitem__
    raise KeyError(f"{self.__class__.__name__} does not support field: {key}")
KeyError: 'Scrapy17Item does not support field: description'
2024-11-25 22:22:27 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 22:22:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 40365,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.940676,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 26, 3, 22, 27, 561085, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 134885,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 66027520,
 'memusage/startup': 66027520,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2024, 11, 26, 3, 22, 26, 620409, tzinfo=datetime.timezone.utc)}
2024-11-25 22:22:27 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 22:26:04 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 22:26:04 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 22:26:04 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 22:26:04 [scrapy.extensions.telnet] INFO: Telnet Password: 2f028804e4f8df76
2024-11-25 22:26:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 22:26:04 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 22:26:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 22:26:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 22:26:04 [scrapy.middleware] INFO: Enabled item pipelines:
['scrapy17.pipelines.Scrapy17Pipeline']
2024-11-25 22:26:04 [scrapy.core.engine] INFO: Spider opened
2024-11-25 22:26:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 22:26:04 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 22:26:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=da73f3537c5860b290c96f96aeaa33c1&wts=1732591275> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 13, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 22:26:05 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 22:26:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 425,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 1.328865,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 26, 3, 26, 5, 513630, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 66043904,
 'memusage/startup': 66043904,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2024, 11, 26, 3, 26, 4, 184765, tzinfo=datetime.timezone.utc)}
2024-11-25 22:26:05 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 22:27:00 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 22:27:00 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 22:27:00 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 22:27:00 [scrapy.extensions.telnet] INFO: Telnet Password: d187cab8200040c2
2024-11-25 22:27:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 22:27:00 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 22:27:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 22:27:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 22:27:01 [scrapy.middleware] INFO: Enabled item pipelines:
['scrapy17.pipelines.Scrapy17Pipeline']
2024-11-25 22:27:01 [scrapy.core.engine] INFO: Spider opened
2024-11-25 22:27:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 22:27:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 22:27:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=da73f3537c5860b290c96f96aeaa33c1&wts=1732591275> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 13, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 22:27:01 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 22:27:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 425,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.809139,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 26, 3, 27, 1, 918455, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 66035712,
 'memusage/startup': 66035712,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2024, 11, 26, 3, 27, 1, 109316, tzinfo=datetime.timezone.utc)}
2024-11-25 22:27:01 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 22:27:42 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy17)
2024-11-25 22:27:42 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.12.9, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.3 (main, Nov  6 2024, 18:32:19) [GCC 13.2.0], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Linux-6.8.0-49-generic-x86_64-with-glibc2.39
2024-11-25 22:27:42 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-25 22:27:42 [scrapy.extensions.telnet] INFO: Telnet Password: 6eccf0aa1db802bc
2024-11-25 22:27:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2024-11-25 22:27:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy17',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'scrapy17.spiders',
 'SPIDER_MODULES': ['scrapy17.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor',
 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
               'like Gecko) Chrome/131.0.0.0 Safari/537.36'}
2024-11-25 22:27:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-25 22:27:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-25 22:27:43 [scrapy.middleware] INFO: Enabled item pipelines:
['scrapy17.pipelines.Scrapy17Pipeline']
2024-11-25 22:27:43 [scrapy.core.engine] INFO: Spider opened
2024-11-25 22:27:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-25 22:27:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-25 22:27:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=da73f3537c5860b290c96f96aeaa33c1&wts=1732591275> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 14, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 22:27:44 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-25 22:27:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 399,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 425,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.943194,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 26, 3, 27, 44, 19129, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'memusage/max': 66064384,
 'memusage/startup': 66064384,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2024, 11, 26, 3, 27, 43, 75935, tzinfo=datetime.timezone.utc)}
2024-11-25 22:27:44 [scrapy.core.engine] INFO: Spider closed (finished)
2024-11-25 22:29:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=da73f3537c5860b290c96f96aeaa33c1&wts=1732591275> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 13, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 22:30:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=da73f3537c5860b290c96f96aeaa33c1&wts=1732591275> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 14, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 22:33:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=da73f3537c5860b290c96f96aeaa33c1&wts=1732591275> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 14, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 22:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=da73f3537c5860b290c96f96aeaa33c1&wts=1732591275> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 30, in parse
    item.bvid = bvid
    ^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/item.py", line 110, in __setattr__
    raise AttributeError(f"Use item[{name!r}] = {value!r} to set field value")
AttributeError: Use item['bvid'] = 'BV1EfBWYNEJA' to set field value
2024-11-25 22:53:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=da73f3537c5860b290c96f96aeaa33c1&wts=1732591275> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 16, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 22:54:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=da73f3537c5860b290c96f96aeaa33c1&wts=1732591275> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 16, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 23:08:57 [scrapy.core.scraper] ERROR: Error processing {'author': '逗比的雀巢',
 'bvid': 'BV1EfBWYNEJA',
 'description': '逗比的雀巢被饿死前的幻想罢了',
 'title': '超超超喜欢我的100个甲方',
 'view_amount': 2717488}
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/pipelines.py", line 15, in process_item
    f.write(f'vedio_bvid:{item[bvid]}')
                               ^^^^
NameError: name 'bvid' is not defined
2024-11-25 23:17:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=c164ae978848a69d211139296c434d42&wts=1732594649.3845878> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 17, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 23:18:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=c164ae978848a69d211139296c434d42&wts=1732594693.0008063> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 17, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 23:18:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=c164ae978848a69d211139296c434d42&wts=1732594696.432928> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 17, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 23:18:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=c164ae978848a69d211139296c434d42&wts=1732594698.2926488> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 17, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 23:18:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://api.bilibili.com/x/web-interface/ranking/v2?rid=0&type=all&web_location=333.934&w_rid=c164ae978848a69d211139296c434d42&wts=1732594717.629272> (referer: None)
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 327, in iter_errback
    yield next(it)
          ^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/python.py", line 368, in __next__
    return next(self.data)
           ^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/referer.py", line 379, in <genexpr>
    return (self._set_referer(r, response) for r in result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/urllength.py", line 57, in <genexpr>
    return (r for r in result if self._filter(r, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/spidermiddlewares/depth.py", line 54, in <genexpr>
    return (r for r in result if self._filter(r, response, spider))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/spidermw.py", line 106, in process_sync
    yield from iterable
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/spiders/bilibili.py", line 17, in parse
    for vedio_info in res["data"]["list"]:
                      ~~~^^^^^^^^
KeyError: 'data'
2024-11-25 23:35:43 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method CoreStats.spider_closed of <scrapy.extensions.corestats.CoreStats object at 0x791f0ab20f50>>
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/crawler.py", line 154, in crawl
    yield self.engine.open_spider(self.spider, start_requests)
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/python/failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/engine.py", line 395, in open_spider
    yield self.scraper.open_spider(spider)
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/python/failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/scraper.py", line 112, in open_spider
    yield self.itemproc.open_spider(spider)
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/pipelines.py", line 13, in open_spider
    self.f = open('bilibili_ranking.txt', 'a', encoding='uft-8')
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
LookupError: unknown encoding: uft-8

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/defer.py", line 400, in maybeDeferred_coro
    result = f(*args, **kw)
             ^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/extensions/corestats.py", line 41, in spider_closed
    assert self.start_time is not None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError
2024-11-25 23:35:43 [twisted] CRITICAL: Unhandled error in Deferred:
2024-11-25 23:35:43 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/crawler.py", line 154, in crawl
    yield self.engine.open_spider(self.spider, start_requests)
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/python/failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/engine.py", line 395, in open_spider
    yield self.scraper.open_spider(spider)
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/python/failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/scraper.py", line 112, in open_spider
    yield self.itemproc.open_spider(spider)
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/pipelines.py", line 13, in open_spider
    self.f = open('bilibili_ranking.txt', 'a', encoding='uft-8')
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
LookupError: unknown encoding: uft-8
2024-11-25 23:36:06 [twisted] CRITICAL: Unhandled error in Deferred:
2024-11-25 23:36:06 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/twisted/internet/defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/crawler.py", line 152, in crawl
    self.engine = self._create_engine()
                  ^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/engine.py", line 102, in __init__
    self.scraper: Scraper = Scraper(crawler)
                            ^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/core/scraper.py", line 101, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/middleware.py", line 86, in _from_settings
    mwcls = load_object(clspath)
            ^^^^^^^^^^^^^^^^^^^^
  File "/home/gellar/opt/pyvenv/lib/python3.12/site-packages/scrapy/utils/misc.py", line 71, in load_object
    mod = import_module(module)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/gellar/Desktop/program/python/xiaoetong/crawler/scrapy16-21/scrapy17/scrapy17/pipelines.py", line 17
    f'
    ^
SyntaxError: unterminated f-string literal (detected at line 17)
